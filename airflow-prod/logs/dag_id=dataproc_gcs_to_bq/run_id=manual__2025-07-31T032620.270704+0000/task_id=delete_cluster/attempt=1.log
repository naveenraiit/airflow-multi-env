[2025-07-31T03:26:30.096+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dataproc_gcs_to_bq.delete_cluster manual__2025-07-31T03:26:20.270704+00:00 [queued]>
[2025-07-31T03:26:30.107+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dataproc_gcs_to_bq.delete_cluster manual__2025-07-31T03:26:20.270704+00:00 [queued]>
[2025-07-31T03:26:30.108+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-31T03:26:30.129+0000] {taskinstance.py:2191} INFO - Executing <Task(DataprocDeleteClusterOperator): delete_cluster> on 2025-07-31 03:26:20.270704+00:00
[2025-07-31T03:26:30.138+0000] {standard_task_runner.py:60} INFO - Started process 1395 to run task
[2025-07-31T03:26:30.143+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dataproc_gcs_to_bq', 'delete_cluster', 'manual__2025-07-31T03:26:20.270704+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/dataproc_gcs_to_bq.py', '--cfg-path', '/tmp/tmp0xvh4u6t']
[2025-07-31T03:26:30.146+0000] {standard_task_runner.py:88} INFO - Job 20: Subtask delete_cluster
[2025-07-31T03:26:30.229+0000] {task_command.py:423} INFO - Running <TaskInstance: dataproc_gcs_to_bq.delete_cluster manual__2025-07-31T03:26:20.270704+00:00 [running]> on host e63302d63f25
[2025-07-31T03:26:30.322+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dataproc_gcs_to_bq' AIRFLOW_CTX_TASK_ID='delete_cluster' AIRFLOW_CTX_EXECUTION_DATE='2025-07-31T03:26:20.270704+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-31T03:26:20.270704+00:00'
[2025-07-31T03:26:30.334+0000] {connection.py:234} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2025-07-31T03:26:30.344+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2025-07-31T03:26:30.345+0000] {dataproc.py:1047} INFO - Deleting cluster: gcs-to-bq-cluster
[2025-07-31T03:26:30.864+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/grpc_helpers.py", line 79, in error_remapped_callable
    return callable_(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/grpc/_channel.py", line 1160, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/grpc/_channel.py", line 1003, in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.NOT_FOUND
	details = "Not found: Cluster projects/target-de/regions/us-east1/clusters/gcs-to-bq-cluster"
	debug_error_string = "UNKNOWN:Error received from peer ipv4:192.178.220.95:443 {created_time:"2025-07-31T03:26:30.859754109+00:00", grpc_status:5, grpc_message:"Not found: Cluster projects/target-de/regions/us-east1/clusters/gcs-to-bq-cluster"}"
>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1014, in execute
    operation = self._delete_cluster(hook)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/dataproc.py", line 1048, in _delete_cluster
    return hook.delete_cluster(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/common/hooks/base_google.py", line 477, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/hooks/dataproc.py", line 369, in delete_cluster
    result = client.delete_cluster(
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/dataproc_v1/services/cluster_controller/client.py", line 1221, in delete_cluster
    response = rpc(
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/retry.py", line 372, in retry_wrapped_func
    return retry_target(
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/retry.py", line 207, in retry_target
    result = target()
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/timeout.py", line 120, in func_with_timeout
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/grpc_helpers.py", line 81, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.NotFound: 404 Not found: Cluster projects/target-de/regions/us-east1/clusters/gcs-to-bq-cluster
[2025-07-31T03:26:30.893+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=dataproc_gcs_to_bq, task_id=delete_cluster, execution_date=20250731T032620, start_date=20250731T032630, end_date=20250731T032630
[2025-07-31T03:26:30.910+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 20 for task delete_cluster (404 Not found: Cluster projects/target-de/regions/us-east1/clusters/gcs-to-bq-cluster; 1395)
[2025-07-31T03:26:30.961+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-07-31T03:26:31.012+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
